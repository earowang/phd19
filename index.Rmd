---
title: "Tidy tools for <br> supporting fluent workflow <br> in temporal data analysis"
type: "seminar"
author: "Earo Wang"
date: ""
output:
  xaringan::moon_reader:
    css: ["libs/remark.css"]
    lib_dir: libs
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://buttons.github.io/buttons.js"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---

```{r initial, echo = FALSE, cache = FALSE, results = 'hide'}
library(knitr)
options(htmltools.dir.version = FALSE, tibble.width = 60, tibble.print_min = 6)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = 'figure/', cache.path = 'cache/', fig.align = 'center', 
  fig.width = 12, fig.show = 'hold', fig.height = 8.5, 
  cache = FALSE, external = TRUE, dev = 'svglite'
)
hook_error = knit_hooks$get('error')
knit_hooks$set(error = function(x, options) {
  y <- strsplit(x, "\n")[[1]]
  z <- paste(strwrap(y, width = 40), collapse = "\n")
  hook_error(z, options)
})
read_chunk('R/theme.R')
read_chunk('R/web.R')
read_chunk('R/flights.R')
```

```{r theme-remark}
```

class: inverse middle

# What is (temporal) data analysis?

---

class: middle

> Data analysis is a process of .orange[inspecting], .orange[cleansing], .orange[transforming], and .orange[modeling] data with the goal of discovering useful information, informing conclusions, and supporting decision-making. <br>
--- [Wikipedia](https://en.wikipedia.org/wiki/Data_analysis)

???

There is a great amount of variation in defining what is a data analysis. According to Wikipedia, data analysis is a process: inspecting, cleansing, transforming, and modelling. And out of this process, we'll learn some knowledge and insights from the data, and make some decisions.

---

class: middle

> .orange[Temporal data analysis] is a process of inspecting, cleansing, transforming, and modeling .orange[time-indexed] data with the goal of discovering useful information, informing conclusions, and supporting decision-making .orange[related to time]. <br>
--- [EaroWiki](https://earo.me)

???

How about temporal data analysis? We still go through the same process, but the data dealt with is time-indexed data. The decisions we're going to make are somehow related to time.

But in order to conduct this process and analyse the data, we need tools. There are many tools out there. We have to carefully choose the good ones to lubricate this process as smoothly as possible. This set of tools, we call them "tidy tools".

---

class: inverse middle

# What are .barcode[messy] tools?

???

Before introducing you tidy tools, I'd like to show you an example of what messy tools are.

---

class: middle

background-image: url(img/model-forecast.png)
background-size: 75%

.pull-left[
]
.pull-right[
.rotate-45[
.alert[
.center[
**2018** <br>
**ETC3550: Applied forecasting**
]
]
]
]

???

This is a slide that I took from last year's Applied forecasting unit taught by Rob. I'm going say this is the messy tools' example. (Sorry, Rob)

It's about fitting three regressions on one data set but with different time trends as regressors. The first two code blocks are straightforward: the first one is linear trend and then forecast 10 steps ahead; the second is exponential trend by taking a log transformation on the response variable but using `lambda = 0` and then forecast.

But the third one looks a bit horrified. The actual idea is simple, fitting a piecewise linear trend. Clearly this `tslm()` doesn't incorporate the piecewise case. So both the lecturer and the students get distracted from the modelling idea but have to understand how to implement the algorithm first. More importantly, this piece of code is very ad hoc. A few tweaks needed for a different data set, and there's possibility to invite mistakes.

---

class: middle

background-image: url(img/model-forecast.png)
background-size: 75%

.pull-left[
]
.pull-right[
.card[
`r emo::ji("thinking")` Should all forecasting students be programmers?
]
]

???

This makes me wonder if students should become programmers first before they can become forecasters.

---

class: middle

background-image: url(img/model-forecast.png)
background-size: 75%

.pull-left[
]
.pull-right[
.card[
`r emo::ji("thinking")` Should all forecasting students be programmers?
]

.rotate-45[
.center[
## [NO!](https://speakerdeck.com/hadley/should-all-statistics-students-be-programmers)
]
]
]

???

Definitely not!

They do have to know how to program to do data analysis. But they don't have to be programmers. Particularly it's not the purpose of that unit.

Now I hope you get a sense of what are messy tools. In terms of sensation, messy tools are smelly.

---

class: inverse middle

# What are ~~messy~~ tidy tools?

???

Contrasting to messy tools, they are tidy tools.

---

class: middle

background-image: url(img/model-fable.png)
background-size: 75%

.pull-left[
]
.pull-right[
.rotate-45[
.alert[
.center[
**2019** <br>
**ETC3550: Applied forecasting**
]
]
]
]

???

This year, Rob is going to teach the same materials but use a different set of tools. You can see the code is clean and succinct.

Most importantly, it helps to communicate the modelling idea in a very clear way. We are going to model this data with three linear regressions. It also addresses the difference between piecewise and a linear trend is by adding knots. Once we're done with model fitting, we forecast them as a whole.

What has been abstracted away is computational implementations and put more emphasis on ideas and expressions. It makes teaching easier and more fun. The door for introducing mistakes is closed. This set of tools are "tidy tools". (Good job, Rob)

---

class: middle

1. Tidy tools are .orange[accessible].
2. Tidy tools are .orange[expressive].
3. Tidy tools are .orange[pipeable].

```r
marathon %>% 
  model(
*   linear = TSLM(Minutes ~ trend()),
*   exponential = TSLM(log(Minutes) ~ trend()),
*   piecewise = TSLM(Minutes ~ trend(knots = c(1940, 1980)))
  ) %>% 
  forecast(h = 10)
```

???

This is my understanding about "tidy tools":

1. Tidy tools are accessible. It means anyone can run this bit of code, anywhere anytime, to produce identical results. There shouldn't be a paywall to prevent users from using it. The source code can be inspected by others as well.
2. Tidy tools are expressive. Tidy tools are code, and code is text. We can express our ideas in text and we can frame our data analysis problems through code. Code is documentation, documenting how we approach the problem. We can easily share plain text across different platforms and groups of people. This goes beyond what point and click software can do. Yes, it is R code. But I believe someone who never used R before, they should be able to quickly get what's happening here. This is the power of expressiveness.
3. Tidy tools are pipeable. Because the input format is the consistent with the output format. We can chain these operations together to build a fluent pipeline and read more naturally. Modelling and then forecasting. It makes possible to have fluent workflow.

---

class: inverse middle

# What is fluent workflow?

---

.left-column[
.center[
## Welcome to
<img src="https://github.com/rstudio/hex-stickers/blob/master/PNG/tidyverse.png?raw=true", height = "200px">
]
]
.right-column[
<br>
<br>
<img src="img/tidy-model.png", width = "100%">
]

### .center[Behind fluent workflow is [tidy data](https://tidyr.tidyverse.org/articles/tidy-data.html).]

???

Data analysis is a process, particularly it's an iterative process.

The tidyverse is a collection of R packages to help with this process quick and tidy.

Why it's important? Before deploying the final model into the production stage, we need to repeat this process many many times. If this model doesn't work, we make some tweaks, and then fit another model. We want this iteration as rapid as possible.

In addition to tidy tools, what's underlying this fluent workflow is tidy data.

The "tidy" stage doesn't mean data cleaning, but refers to making the data in a right shape, a uniform shape that is shared by these three stages in this circle.

With the tidyverse, we have such a fluent pipeline to handle data analysis. But when you have time series data and want to do time series analysis ...

---

.left-column[
.center[
## Welcome to <br> .red[time series analysis]
]
]
.right-column[
<br>
<br>
<img src="img/ts-model.png", width = "100%">
]

### .center[WAT!`r emo::ji("scream")`]

???

This is what you experience.

Small data lives in csv files, big data stays in database. But most time, the form of the data at the "import" stage deviates a lot from the current time series objects that are designed for modelling. When doing transformation and visualisation, different data shapes are expected. We do not have a uniform shape for lubricating this process for time series. There's no formal guidance how to reshape the data for modelling purpose.

Screaming out "WAT" is the natural response to this workflow. Let me share my "WAT" moment.

---

.left-column[
## .center[WAT!`r emo::ji("scream")`]
]
.right-column[
```r
# Put them into a big matrix
ltraffics <- list(as.bf.cpu, as.bf.busy, as.bf.memory, as.bf.page,
                  as.gq.cpu, as.gq.busy, as.gq.memory, as.gq.page,
                  as.ir.cpu, as.ir.busy, as.ir.memory, as.ir.page,
                  ...
                  hs.gq.cpu, hs.gq.busy, hs.gq.memory, hs.gq.page,
                  hs.ir.cpu, hs.ir.busy, hs.ir.memory, hs.ir.page,
                  hs.ne.cpu, hs.ne.busy, hs.ne.memory, hs.ne.page,
                  hs.sg.cpu, hs.sg.busy, hs.sg.memory, hs.sg.page)
indcols <- sapply(ltraffics, ncol)
cs <- cumsum(c(1, indcols))
totalcols <- sum(indcols)
traffics <- matrix(, nrow = 719, ncol = totalcols)
for (i in 1L:length(ltraffics)) {
  idx <- cs[i]:(cs[i + 1] - 1L)
  traffics[, idx] <- as.matrix(ltraffics[[i]][1:719, ])
}
```
]

???

When I was doing my honours project years agos, I needed to compute a bunch of time series features on yahoo web traffic data. 

The script shows I put multiple csvs into a big time series matrix. But it took me a while to understand what past me was doing.

When I revisit this code, I started to realise there's something fundamentally wrong here. Multiple observational units and multiple measurements have been put into one object, which isn't appropriate for the traditional time series structure.

---

background-image: url(img/tsibble-model.png)
background-size: 70%
background-position: 91% 38%

.left-column[
## .center[Welcome <br> to <br> the tidyver.red[ts]]
]
.right-column[
.animated.slower.rollIn.delay-3s[
.pipeline[<img src="img/tsibble.png", height = "150px">]
]
]

### .bottom[.center[Tsibble defines tidy data in temporal context.]]

???

So my work is going to smooth out those rough edges and fill the gap of tidy data in temporal context. We're going to call this new data structure---"tsibble".

You know I'm serious about this work, bc it has a logo.

Next I'm going to demonstrate this whole data process with tsibble and showcase the value of it.

---

class: inverse middle

# .orange[Temporal] data analysis <br> doesn't make sense <br> without .orange[time-indexed] data.

???

Data analysis cannot live w/o data.

---

class: center middle

## Parallel data stories

.pull-left[
<img src="img/website.png", height = "320px">

### Web traffic at [earo.me](http://earo.me)
]
.pull-right[
<img src="img/us-airlines.png", height = "320px">

### Airline traffic in the US
]

???

I'm going to share with you two data stories simultaneously.

The LHS is daily users visiting my personal website <earo.me>. I own this domain and the website since 2012. The RHS is on-time performance for domestic airlines in the States. One personal, one national. One small data, and one big data.

---

.pull-left[
### Web traffic

```{r load-web}
```
]
.pull-right[
### Airline traffic

```{r load-flights}
```
]

???

How the data looks like?

My data is quite simple, with 1000 obs and 2 variables. The `Date` column provides the time context. and how many visitors.

This data starts from the day when I started my PhD until yesterday. It has a sad beginning that nobody visited my website in the early days.

On the other hand, airline data contains 5M obs and 22 variables. The `sched_dep_datetime` column gives the date-times. Other variables include the meta info describing the flights and on-time performance metrics. It is an event data set.

They already arrived in the tidy shape, with clearly defined observations and variables. Now we need to declare them as temporal data using tsibble.

---

class: inverse middle

# .blue[1.] Tsibble is <br> data representation <br> for tidy temporal data.

<hr>

<img src="img/tsibble-semantics.png", height = "120px">

???

Tsibble is a multi-faceted product.

First of all, tsibble represents tidy temporal data.

A tsibble has to be tidy data first. Data is organised in the common rectangular form: each row is an observation; each column holds a variable. But temporal data is more of a contextual data object. So on top of the tidy data, column variables require more meanings: index for time support, key for defining identities over time, and the rest are measurements.

---

.top[<img src="img/tsibble-semantics.png", height = "80px">]

## Contextual semantics

.pull-left[
### .brown[1.] Index <i class="far fa-clock"></i>

Time indices provide a contextual basis for temporal data.

* acknowledge the diversity of time representations
* respect time zones
* allow regular/irregular intervals
]
.pull-right[
### .brown[2.] Key <i class="fas fa-users"></i>

Key identifies observational units recorded over time.

* comprise empty, one or more variables
* known a priori by analysts
* determine unique time indices
]

???

Let me elaborate index and key more.

The index variable consists of time indices that provide a contextual basis for temporal data.

A variety of time represenations exist in the wild, the common ones you saw before, dates and date-times, as well as intradays and intervals from one time point to another. Tsibble supports all of them, as long as they can be ordered from past to future.

Unlike other time series objects, tsibble respects time zones, will not ignore them and not convert them to UTC. 

Temporal data can be regular and irregularly spaced in time.

And the key can consist of empty, one or more variables. It is typically known for analysts. Each observational unit in the key, only allows unique time indices.

---

class: middle

## Declare a tsibble

.pull-left[
```{r web-tsibble, echo = TRUE}
```

```{r highlight.output = 1}
web_ts
```

]

???

Can these two data sets meet the tsibble definition in the first instance?

--

.pull-right[
```{r try-tsibble, echo = TRUE, error = TRUE}
```
### .red[Oops!]
]

---

## <i class="fas fa-search"></i> duplicates and <i class="fas fa-wrench"></i> them

```{r find-duplicate, echo = TRUE, eval = FALSE}
```

```{r highlight.output = c(4, 8)}
flights %>% 
  duplicates(key = id(flight_num), index = sched_dep_datetime) %>% 
  print(width = 100)
```

---

```{r find-duplicate-lgl}
```

```{r tsibble, echo = TRUE}
```

```{r highlight.output = 1:2}
print(flights_ts, width = 70)
```

---

<img src="img/tsibble-pipeline.png" height=580px>

---

.top[<img src="img/website.png", height = "80px">]

## In harmony with grammar of graphics

```{r web-ggplot, fig.height = 2.5, echo = TRUE}
```

---

.top[<img src="img/website.png", height = "80px">]

## In harmony with grammar of graphics

```{r web-geom, fig.height = 2.5, echo = TRUE}
```

---

class: inverse middle

# .blue[2.] Tsibble is <br> a domain specific language in <i class="fab fa-r-project"></i> <br> for wrangling temporal data.

<hr>

### [Good fluent APIs take a while to build.](https://martinfowler.com/bliki/FluentInterface.html)

???

Naming a function is difficult.

I like a verb that describes the software development is "craft".

---

.pull-left[
**.brown[1.] Vector functions**
* `yearmonth()`/`yearquarter()`
* `time_in()`
* `difference()`

**.brown[3.] Window family**
* `slide()`/`future_slide()`
* `tile()`/`future_tile()`
* `stretch()`/`future_stretch()`
]
.pull-right[
**.brown[2.] Table verbs**
* `scan_gaps()`/`fill_gaps()`
* `index_by()`/`group_by_key()`
* `filter_index()`

**.brown[4.] Extend tsibble**
* `index_valid()`
* `pull_interval()`
* `new_tsibble()`
]

???

4 blocks of functions

Each focuses on doing one little thing and doing it well.

---

class: center

.left-column[
## Scroll down <br> for <br> the full vocabulary
]
.right-column[
<br>

<iframe src="https://tsibble.tidyverts.org/reference/index.html" frameborder="0" height="400" width="750">
</iframe>

### [tsibble.tidyverts.org](https://tsibble.tidyverts.org)
]

---

class: center middle

<img src="img/tsibble.png" height=180px>

## standing on the shoulders of giants

.animated.fadeInRight.slow[
.orange[
```{r tidyverse, comment = ""}
tidyverse::tidyverse_logo()
```
]
]

---

.pull-left[
<img src="https://github.com/rstudio/hex-stickers/blob/master/PNG/tidyverse.png?raw=true", height = "80px">
```{r web-dplyr-select, echo = TRUE}
```
]
.pull-right[
<img src="img/tsibble.png" height=80px>
```{r web-tsibble-select, echo = TRUE, message = TRUE}
```
]

---

.pull-left[
<img src="https://github.com/rstudio/hex-stickers/blob/master/PNG/tidyverse.png?raw=true", height = "80px">
```{r web-dplyr-summarise, echo = TRUE}
```
]
.pull-right[
<img src="img/tsibble.png" height=80px>
```{r web-tsibble-summarise, echo = TRUE}
```
]

---

.top[<img src="img/website.png", height = "80px">]

## Compose prose

.pull-left[
```{r web-year, echo = TRUE, results = "hide"}
```
```{r}
web_year
```
]
.pull-right[
```{r web-year-bar, fig.height = 8}
```
]

---

.top[<img src="img/us-airlines.png", height = "80px">]

```{r sel-flights, echo = TRUE}
```
.pull-left[
```{r}
sel_delay
```
]
.pull-right[
```{r sel-flights-plot, fig.height = 7}
```
]

---

class: inverse middle

# .blue[3.] Tsibble rolls with <br> functional programming.

<hr>

### [FP focuses on expressions instead of for-loop statements.](https://en.wikipedia.org/wiki/Functional_programming)

---

.pull-left[
```{r for-loop, echo = -1}
options(width = 35)
x <- 1:12
ma_x1 <- double(length = length(x) - 1)
for (i in seq_along(ma_x1)) {
  ma_x1[i] <- mean(x[i:(i + 1)]) #<<
}
ma_x1
ma_x2 <- double(length = length(x) - 2)
for (i in seq_along(ma_x2)) {
  ma_x2[i] <- mean(x[i:(i + 2)]) #<<
}
ma_x2
```
]
.pull-right[
.bottom[
### `r emo::ji("arrow_left")` For loops
]
]

---

.pull-left[
```{r for-loop, echo = -1}
```
]
.pull-right[
```{r echo = -1}
options(width = 35)
slide_dbl(x, ~ mean(.), .size = 2)
slide_dbl(x, ~ mean(.), .size = 3)
```
.bottom[
### `r emo::ji("arrow_up")` Functionals
]
]

---

.left-column[
## .center[`r emo::ji("female_detective")`]
## .center[`r emo::ji("woman_technologist")`]
## .center[`r emo::ji("woman_scientist")`]
## .center[`r emo::ji("woman_artist")`]
## .center[`r emo::ji("woman_firefighter")`]
## .center[`r emo::ji("woman_astronaut")`]
## .center[`r emo::ji("woman_superhero")`]
## .center[`r emo::ji("sorceress")`]
]
.right-column[
<details open="open">
<summary>Rolling window animation</summary>
<img src="https://tsibble.tidyverts.org/reference/figures/animate-1.gif" align="center" />
</details>

<br>
* as simple as moving average calculation
* as complex as rolling model fitting
* time series cross validation
* arbitrary types of inputs & outputs
* parallel processing
]

---

class: middle center

<img src="img/tsibble.png", height = "250px"><img src="img/fable.png", height = "250px">

## The future is just around the corner.

---

background-image: url(img/tsibble-model.png)
background-size: 70%
background-position: 91% 38%

.left-column[
## .center[Takeaway]
]
.right-column[
.animated.slower.rollIn.delay-1s[
.pipeline[<img src="img/tsibble.png", height = "150px">]
]
]

### .bottom[.center[Tsibble provides <br> fundamental computing infrastructure.]]

---

.pull-left[
```{r web-fcast, echo = TRUE, fig.show = "hide"}
```
]
.pull-right[
.top[<img src="img/understand.png", height = "120px">]
<br>
<details>
<summary>Where am I heading?</summary>
<img src="img/xkcd-bar.gif", width = "100%">
</details>
]

---

class: inverse middle

# .blue[<i class="fas fa-step-backward"></i>] Calendar-based graphics

---

## Showcase

.pull-left[
### .center[Everyday running path]
<img src="https://pbs.twimg.com/media/DSKO3xMUEAAZ8Ga.jpg", width = "100%">
]
.pull-right[
### .center[Auckland bus delay]
<img src="https://pbs.twimg.com/media/DU0d5cVVAAA7OWw.jpg", width = "100%">
]

---

class: inverse middle

# Missingness in time .blue[<i class="fas fa-step-forward"></i>]

---

.left-column[
## .center[Types <br> of <br> missings in time]
]
.right-column[
.center[
<img src="img/miss-types-1.png", width = "70%">
]
]

---

class: inverse middle

# `r emo::ji("star2")` Impact

---

class: middle

.pull-left[
### sugrrants <a class="github-button" href="https://github.com/earowang/sugrrants" data-size="large" data-show-count="true" aria-label="Star earowang/sugrrants on GitHub">Star</a>
`r emo::ji("1st_place_medal")` 2018 Best student paper award from ASA Section on Statistical Graphics

<hr>

### tsibble <a class="github-button" href="https://github.com/tidyverts/tsibble" data-size="large" data-show-count="true" aria-label="Star tidyverts/tsibble on GitHub">Star</a>
`r emo::ji("trophy")` 2019 John Chambers Statistical Software Award from ASA Section on Statistical Computing
]
.pull-right[
Total downloads, as of `r Sys.Date() - 1`
```{r software-impact, fig.height = 10}
library(cranlogs)
pkgs_dl <- cran_downloads(c("sugrrants", "tsibble"), from = "2017-07-28")
pkgs_dl %>% 
  group_by(package) %>% 
  summarise(count = sum(count)) %>% 
  ggplot(aes(x = package, y = count)) +
  geom_col(aes(fill = package)) +
  geom_text(aes(label = count), vjust = -0.5, size = 10) +
  geom_text(aes(y = 0, label = package), hjust = -0.1, vjust = -2, size = 15, angle = 45) +
  guides(fill = "none")
```
]

---

class: inverse middle

# `r emo::ji("open_book")` Research compendium

<hr>

### A form of publication contains all data and software for better reproducibility, besides the text and figures.
**Marwick et al. (2018) [peerj.com/preprints/3192](https://peerj.com/preprints/3192/)**

---

class: middle

```{r}
library(data.tree)
root <- Node$new(".")
desc <- root$AddChild("DESCRIPION # Lists of packages used for thesis")
readme <- root$AddChild("README.md  # Instructions on package's installation and etc.")
scripts <- root$AddChild("scripts/   # R code for analysis")
r <- root$AddChild("R/         # Reusable R functions")
rmd <- root$AddChild("Rmd/       # R Markdown for thesis document")
data <- root$AddChild("data/      # Cleaned data used for thesis document")
data_raw <- root$AddChild("data-raw/  # Raw data and scripts to clean data")
docker <- root$AddChild("Dockerfile")
others <- root$AddChild("...")
root
```


### .center[<i class="fab fa-github"></i> [earowang/thesis](https://github.com/earowang/thesis)]

## .center[Persistent reproducibility]

---

class: center middle

<iframe src="https://thesis.earo.me/preface.html" frameborder="0" height="400" width="850">
</iframe>

### <i class="fas fa-link"></i> [thesis.earo.me](https://thesis.earo.me)

## Open access

---

class: inverse

.left-column[
.animated.pulse.infinite[
# .red[.center[`r emo::ji("heart")`]]
]
]
.right-column[
.portrait[
![](img/di.jpg)
Di
]
.portrait[
![](https://pbs.twimg.com/profile_images/1103150025981321216/dV3Wz_ql_400x400.png)
Rob
]
<br>
.portrait[
![](https://pbs.twimg.com/profile_images/2162872292/Photo_on_2012-02-20_at_08.18_400x400.jpg)
Heike
]
.portrait[
![](https://pbs.twimg.com/profile_images/901030601490182145/Un598Dz3_400x400.jpg)
Mitch
]
.portrait[
![](https://pbs.twimg.com/profile_images/1035681370251526145/Ks3Mbojm_400x400.jpg)
Stuart
]
.portrait[
![](img/david.jpeg)
David
]
.portrait[
![](https://pbs.twimg.com/profile_images/1588338728/peng7_400x400.png)
Roger
]
.portrait[
![](img/numbat-painted.png)
NUMBATs
]
.portrait[
![](img/Rlogo.png)
<i class="fab fa-r-project"></i> community
]
]

---

class: inverse middle center

# .animated.zoomOut.slower.delay-2s[.large[FIN]]
